---
title: "Projet"
output: html_document
date: "2023-12-11"
---
##Examen des Données:

Avant de se plonger dans des analyses spécifiques, il est essentiel d'examiner les données pour comprendre leur structure, leurs variables et leurs statistiques de base. Nous chargerons les données, examinerons les premières lignes et passerons en revue les types de données et les statistiques sommaires.
```{r setup, include=FALSE}

library(readr)
#library(tidyverse)
library(dplyr)
library(ggplot2)
library(stats)


# Lecture des ensembles de données
day_data <- read_csv("bike+sharing+dataset/day.csv")
hour_data <- read_csv("bike+sharing+dataset/hour.csv")

```




```{r cars}
# Affichage des premières lignes de l'ensemble de données journalier
head(day_data)

# Résumé de l'ensemble de données journalier
summary(day_data)

# Structure de l'ensemble de données journalier
str(day_data)

```


```{r pressure, echo=FALSE}
# Affichage des premières lignes de l'ensemble de données horaires
head(hour_data)

# Résumé de l'ensemble de données horaires
summary(hour_data)

str(hour_data)
```
```{r}
sum(is.na(hour_data))
sum(is.na(day_data))
```
```{r}
sum(duplicated(hour_data))
sum(duplicated(day_data))
```


Nous allons maintenant examiner nos données pour répondre aux questions spécifiques posées.

##Changements de Température Selon les Saisons
#Comment les températures changent-elles selon les saisons ? Quelles sont les températures moyennes et médianes ?

Pour répondre à cette question, nous analyserons la température (temp) par saison et calculerons les moyennes et médianes.
```{r}
library(dplyr)

# Calcul de la température moyenne et médiane par saison
temperature_stats <- day_data %>%
  group_by(season) %>%
  summarise(mean_temp = mean(temp, na.rm = TRUE),
            median_temp = median(temp, na.rm = TRUE))

# Affichage des résultats
print(temperature_stats)

```
Cette partie du code permet d'obtenir une vue d'ensemble des températures par saison, ce qui est crucial pour comprendre comment les conditions météorologiques influencent l'utilisation des vélos.


##Y a-t-il une corrélation entre la température (temp/atemp) et le nombre total de locations de vélos ?

Nous examinerons la corrélation entre la température, la température ressentie et le nombre total de locations.

```{r}

# Charger la bibliothèque corrplot si ce n'est pas déjà fait
# Si vous ne l'avez pas déjà installée, exécutez install.packages("corrplot")
library(corrplot)

# Calculer la température moyenne entre temp et atemp
day_data$mean_temp_atemp <- rowMeans(day_data[, c("temp", "atemp")])

# Calculer la matrice de corrélation
correlation_matrix <- cor(day_data[, c("temp", "atemp", "mean_temp_atemp", "cnt")], use = "complete.obs")

# Visualiser la matrice de corrélation
corrplot(correlation_matrix, method = "circle")


```

#Quelles sont les températures moyennes, l'humidité, la vitesse du vent et les locations totales par mois ?

Nous calculerons ces moyennes pour chaque mois pour identifier des tendances saisonnières.


Les valeurs de température, d'humidité et de vitesse du vent sont normalisées. La température moyenne est la plus élevée en juillet (0.755) et la plus basse en décembre (0.324). L'humidité est relativement stable tout au long de l'année avec une légère augmentation pendant les mois d'été. La vitesse du vent moyenne est généralement la plus faible en juillet (0.166) et la plus élevée en avril (0.234). Le nombre de locations de vélos est le plus élevé en juin (5772.37) et le plus bas en janvier (2176.34).
```{r}
# Calcul des moyennes mensuelles
monthly_averages <- day_data %>%
  group_by(mnth) %>%
  summarise(
    mean_temp = mean(temp, na.rm = TRUE),
    mean_humidity = mean(hum, na.rm = TRUE),
    mean_windspeed = mean(windspeed, na.rm = TRUE),
    mean_rentals = mean(cnt, na.rm = TRUE)
  )

# Affichage des moyennes mensuelles
print(monthly_averages)

```


#La température est-elle associée aux locations de vélos (enregistrés vs occasionnels) ?

Nous étudierons comment la température affecte différemment les utilisateurs enregistrés et occasionnels.
```{r}
# Association de la température avec les locations de vélos
rentals_by_temp <- day_data %>%
  group_by(temp) %>%
  summarise(mean_casual = mean(casual),
            mean_registered = mean(registered))

# Visualisation
ggplot(rentals_by_temp, aes(x = temp)) +
  geom_line(aes(y = mean_casual, color = "Occasionnel")) +
  geom_line(aes(y = mean_registered, color = "Enregistré")) +
  labs(title = "Locations de Vélos par Température",
       x = "Température Normalisée",
       y = "Locations Moyennes")
```


```{r}
# Calcul de la corrélation entre température et locations pour les utilisateurs enregistrés et occasionnels
correlation_temp_users <- day_data %>%
  select(temp, casual, registered) %>%
  cor(use = "complete.obs")

# Affichage de la matrice de corrélation
print(correlation_temp_users)

```


Calculer la corrélation entre la température et les locations pour les utilisateurs enregistrés et occasionnels.

Résumer comment les locations moyennes varient avec la température en regroupant les températures par intervalles puis en calculant le nombre moyen de locations pour chaque groupe.
????????????????????je ne sais pas




```{r}
# Conversion de 'dteday' en format de date
day_data$dteday <- as.Date(day_data$dteday, format="%Y-%m-%d")

# Tracé de 'cnt' vs 'dteday'
ggplot(day_data, aes(x=dteday, y=cnt)) + 
  geom_line() + 
  labs(title="Nombre de locations de vélos par jour", 
       x="Date", 
       y="Nombre total de locations de vélos") +
  theme(axis.text.x = element_text(angle=90, hjust=1))

```
Il y a une saison annuelle, on voit une tendance ( mois plus chauds implique hausse des locations et une baisse pendant les mois plus froids). La variance est plus au moins constante.



```{r}


# Conversion de 'dteday' en format de date
day_data$dteday <- as.Date(day_data$dteday, format="%Y-%m-%d")

# Identifier les valeurs aberrantes, par exemple en utilisant la méthode des écarts interquartiles
IQR_values <- IQR(day_data$cnt)
quantiles <- quantile(day_data$cnt, probs=c(.25, .75))
cap <- quantiles[2] + 1.5 * IQR_values
floor <- quantiles[1] - 1.5 * IQR_values

# Filtrer les valeurs aberrantes
day_data <- day_data %>%
  filter(cnt >= floor & cnt <= cap)

# Lisser la série temporelle en utilisant une moyenne mobile avec la fonction 'filter' du package 'stats'
day_data$cnttimeseries <- ts(day_data$cnt, frequency = 12)

hw_model <- HoltWinters(day_data$cnttimeseries)

plot(hw_model)

```



```{r}
# Extraire les valeurs prévues à partir du modèle HoltWinters
fitted_values <- hw_model$fitted[, "xhat"]

# Ajouter la fréquence appropriée à la série lissée (remplacez 12 par la fréquence appropriée)
smoothed_ts <- ts(fitted_values, frequency = 12)

plot(smoothed_ts)

result <- adf.test(smoothed_ts, alternative = "stationary")

# Afficher les résultats du test
print(result)

```
La série n'est pas stationnaire (variance constante mais moyenne variable) le test de Dicker Fuller confirme cela avec une p_value = 0.96 (hyp nulle : non stationnaire), on distingue une saison (qui se répète deux fois).

```{r}
# Appliquer la différenciation saisonnière
diff_series <- diff(smoothed_ts, lag=12)

# Tracer la série différenciée
plot(diff_series, main="Série Temporelle Différenciée", xlab="Temps", ylab="Différences")

```


```{r}
pacf(diff_series,lag.max=100, main="PACF")
```


```{r}
acf(diff_series,lag.max= 100, main="ACF")

```
On remarque le PACF décroit exponentiellement, et sur le ACF on lit : MA(9)
On remarque le ACF décroit exponentiellement, et sur le PACF on lit : AR(2)

Concernant les saisons, sur le ACF ça décroit et sur le PACF on lit P = 4
sur le PACF ça décroit et sur le ACF on lit Q=4

```{r}
#MA(9) ou AR(2)
#ARIMA(2,0,0)(3,1,0)h=12 ***
#ARIMA(0,0,9)(4,1,0)h=12 ****
#ARIMA(2,0,0)(0,1,2)h=12 *
#ARIMA(0,0,9)(0,1,2)h=12 **

```



```{r}
model_m1 <- arima(smoothed_ts, order = c(2, 0, 0), seasonal = list(order = c(3, 1, 0), period = 12))

residuals_m1 <- residuals(model_m1)
plot(residuals_m1)
#mean=0 var=cte 
par(mfrow = c(2, 1))
acf(residuals_m1, main = "ACF of Residuals")
pacf(residuals_m1, main = "PACF of Residuals")
#no significant peak on the ACF and PACF

Box.test(residuals_m1, type = "Ljung-Box")
#p-value= 0.8102
aic_value_m1 <- AIC(model_m1)
cat("AIC du modèle m1:", aic_value_m1, "\n")
#AIC=10179.9 
```



```{r}
model_m2 <- arima(smoothed_ts, order = c(0, 0, 9), seasonal = list(order = c(4, 1, 0), period = 12))

residuals_m2 <- residuals(model_m2)
plot(residuals_m2)
#mean=0 var=cte 
par(mfrow = c(2, 1))
acf(residuals_m2, main = "ACF of Residuals")
pacf(residuals_m2, main = "PACF of Residuals")
#no significant peak on the ACF and PACF

Box.test(residuals_m2, type = "Ljung-Box")
#p-value= 0.7992
aic_value_m2 <- AIC(model_m2)
cat("AIC du modèle m2:", aic_value_m2, "\n")
#AIC=10213.16 
```
```{r}
model_m3 <- arima(smoothed_ts, order = c(2, 0, 0), seasonal = list(order = c(0, 1, 2), period = 12))

residuals_m3 <- residuals(model_m3)
plot(residuals_m3)
#mean=0 var=cte 
par(mfrow = c(2, 1))
acf(residuals_m3, main = "ACF of Residuals")
pacf(residuals_m3, main = "PACF of Residuals")
#no significant peak on the ACF and PACF

Box.test(residuals_m3, type = "Ljung-Box")
#p-value= 0.7226
aic_value_m3 <- AIC(model_m3)
cat("AIC du modèle m3:", aic_value_m3, "\n")
#AIC=10131.05  
```

```{r}
model_m4 <- arima(smoothed_ts, order = c(0, 0, 9), seasonal = list(order = c(0, 1, 2), period = 12))

residuals_m4 <- residuals(model_m4)
plot(residuals_m4)
#mean=0 var=cte 
par(mfrow = c(2, 1))
acf(residuals_m4, main = "ACF of Residuals")
pacf(residuals_m4, main = "PACF of Residuals")
#no significant peak on the ACF and PACF

Box.test(residuals_m4, type = "Ljung-Box")
#p-value= 0.8202
aic_value_m4 <- AIC(model_m4)
cat("AIC du modèle m4:", aic_value_m4, "\n")
#AIC=10206.35 

```
Le meilleur modèle a l'air d'être le modèle m2 : ARIMA(0,0,9)(4,1,0)h=12


```{r}
library(forecast)

# Ajuster un modèle ARIMA automatiquement sur les données stationnaires
# Supposons que 'diff_log_cnt_clean' est votre série temporelle prétraitée
model <- auto.arima(smoothed_ts)


# Afficher le résumé du modèle ajusté
summary(model)
```

##Désaisonnaliser les données :
```{r}
#Désaisonnaliser les données 
diff_cnt <- diff(day_data$cnt, lag=12)
plot(diff_cnt)


```
```{r}
pacf(diff_cnt, main="PACF")
```
L'ACF présente une décroissance rapide après le premier décalage, ce qui suggère un terme MA. Si ce décalage est le seul significatif, cela pourrait indiquer un modèle MA(1).


Le PACF montre un pic significatif au premier décalage et ensuite il se stabilise, ce qui est typique d'un modèle AR(1).

```{r}

acf(diff_cnt, main="ACF")
```
```{r}
#AR(1)
#MA(3)
#ARIMA(1,0,0)
#ARIMA(0,0,3)


```
```{r}
model_m1_deseasonal <- arima(diff_cnt, order = c(1, 0, 0))

residuals_m1_deseasonal <- residuals(model_m1_deseasonal)
plot(residuals_m1_deseasonal)
#mean=0 var=cte 
par(mfrow = c(2, 1))
acf(residuals_m1_deseasonal, main = "ACF of Residuals")
pacf(residuals_m1_deseasonal, main = "PACF of Residuals")
#no significant peak on the ACF and PACF

Box.test(residuals_m1_deseasonal, type = "Ljung-Box")
#p-value= 0.5961
aic_value_m1_deseasonal<- AIC(model_m1_deseasonal)
cat("AIC du modèle m4:", aic_value_m1_deseasonal, "\n")
#AIC=12343.73  

```
```{r}
model_m2_deseasonal <- arima(diff_cnt, order = c(0, 0, 3))

residuals_m2_deseasonal <- residuals(model_m2_deseasonal)
plot(residuals_m2_deseasonal)
#mean=0 var=cte 
par(mfrow = c(2, 1))
acf(residuals_m2_deseasonal, main = "ACF of Residuals")
pacf(residuals_m2_deseasonal, main = "PACF of Residuals")
#no significant peak on the ACF and PACF

Box.test(residuals_m2_deseasonal, type = "Ljung-Box")
#p-value= 0.9679
aic_value_m2_deseasonal<- AIC(model_m2_deseasonal)
cat("AIC du modèle m2:", aic_value_m2_deseasonal, "\n")
#AIC=12346.61    
```
Le meilleur modèle en prenant en compte the Parsimony principle est le modèle m1 : AR(1)



```{r}
# Installer le package forecast si nécessaire

# Charger le package forecast
library(forecast)

# Ajuster un modèle ARIMA automatiquement sur les données stationnaires
fit_arima <- auto.arima(diff_cnt)

# Afficher le résumé du modèle ajusté
summary(fit_arima)

```


```{r}

residuals_adjusted_deseasonal <- residuals(fit_arima)
plot(residuals_adjusted_deseasonal)
#mean=0 var=cte 
par(mfrow = c(2, 1))
acf(residuals_adjusted_deseasonal, main = "ACF of Residuals")
pacf(residuals_adjusted_deseasonal, main = "PACF of Residuals")
#no significant peak on the ACF and PACF

Box.test(residuals_adjusted_deseasonal, type = "Ljung-Box")

aic_value_adjusted<- AIC(fit_arima)
cat("AIC du modèle auto arima:", aic_value_adjusted, "\n")
    

```
Le modèle choisi plus haut, AR(1) donne un AIC légèrement plus élevé, de plus, il est plus simple. et d'après le principe de parsimony, il est préférable de choisir le plus simple.

```{r}
library(forecast)
forecasts <- forecast(model_m1_deseasonal, h=25)
plot(forecasts)

```
```{r}


cat(length(day_data$cnt))
# Diviser les données en ensembles d'entraînement et de test
train_data <- window(day_data$cnt, start = 1, end = 700)
test_data <- window(day_data$cnt, start = 701)

```
```{r}
train_data_ts <- ts(train_data)
test_data_ts <- ts(test_data)

ts.plot(train_data_ts)
```


```{r}
diff_train <- diff(train_data_ts, frequency=12)
plot(diff_train)
```
```{r}

```

```{r}
# Ajuster un modèle ARIMA manuellement sur l'ensemble d'entraînement
manual_model <- arima(train_data, order = c(2, 0, 0), seasonal = list(order = c(4, 1, 0), period = 12))

# Ajuster un modèle ARIMA automatiquement sur l'ensemble d'entraînement
auto_model <- auto.arima(train_data)

# Prévoir les prochaines 25 observations avec les deux modèles
manual_forecast <- forecast(manual_model, h = 25)
auto_forecast <- forecast(auto_model, h = 25)

# Plot des prévisions et des données réelles
plot(test_data, col = "blue", ylim = range(test_data, manual_forecast$mean, auto_forecast$mean),
     main = "ARIMA Forecast Comparison", xlab = "Time", ylab = "Value")
lines(manual_forecast$mean, col = "red", lty = 2, lwd = 2)
lines(auto_forecast$mean, col = "green", lty = 2, lwd = 2)

# Ajouter une légende
legend("topright", legend = c("Observed", "Manual Forecast", "Auto Forecast"),
       col = c("blue", "red", "green"), lty = c(1, 2, 2), lwd = 2)
```
